{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PCA"
      ],
      "metadata": {
        "id": "4TLG8Aou5i-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQ0jX3y15LNz"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# PCA on a Normal Dataset (data.csv)\n",
        "# =====================================\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------\n",
        "# 1. LOAD DATA\n",
        "# ---------------------------\n",
        "data = pd.read_csv('/content/customers.csv')\n",
        "print(\"First 5 rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# ---------------------------\n",
        "# 2. DATA CLEANING\n",
        "# ---------------------------\n",
        "# Drop duplicates and handle missing values\n",
        "data = data.drop_duplicates()\n",
        "data = data.fillna(data.mean())\n",
        "\n",
        "# ---------------------------\n",
        "# 3. FEATURE SELECTION\n",
        "# ---------------------------\n",
        "# Assuming the last column is the target\n",
        "X = data.drop('Spending_Score', axis=1)\n",
        "y = data['Spending_Score']\n",
        "\n",
        "# ---------------------------\n",
        "# 4. SCALING (Important!)\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. APPLY PCA\n",
        "# ---------------------------\n",
        "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"\\nExplained Variance Ratio:\", pca.explained_variance_ratio_)\n",
        "print(\"Total Variance Captured:\", sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# ---------------------------\n",
        "# 6. VISUALIZATION\n",
        "# ---------------------------\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA on Normal Dataset')\n",
        "plt.colorbar(label='Target Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQGneVLr6UST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}