{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "4TLG8Aou5i-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQ0jX3y15LNz"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# LOGISTIC REGRESSION FULL PRACTICAL CODE\n",
        "# =====================================\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# ---------------------------\n",
        "# 1. DATA LOADING\n",
        "# ---------------------------\n",
        "# Example CSV should contain columns like ['feature1', 'feature2', ..., 'target']\n",
        "# where 'target' contains binary values (0/1 or Yes/No)\n",
        "data = pd.read_csv('/content/customers.csv')\n",
        "\n",
        "print(\"First 5 rows of dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# ---------------------------\n",
        "# 2. DATA CLEANING\n",
        "# ---------------------------\n",
        "# Remove duplicates\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Handle missing values\n",
        "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
        "data = data.fillna(data.mean())\n",
        "\n",
        "# ---------------------------\n",
        "# 3. FEATURE SELECTION\n",
        "# ---------------------------\n",
        "X = data.drop('Spending_Score', axis=1)\n",
        "y = data['Spending_Score']\n",
        "\n",
        "# ---------------------------\n",
        "# 4. DATA PREPROCESSING\n",
        "# ---------------------------\n",
        "# Scale features for better model performance\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. TRAIN-TEST SPLIT\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. MODEL TRAINING\n",
        "# ---------------------------\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. PREDICTION\n",
        "# ---------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 8. EVALUATION\n",
        "# ---------------------------\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQGneVLr6UST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}